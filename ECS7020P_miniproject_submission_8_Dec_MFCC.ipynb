{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91MsGMTna_P9"
   },
   "source": [
    "# ECS7020P mini-project submission\n",
    "\n",
    "The mini-project has two separate components:\n",
    "\n",
    "\n",
    "1.   **Basic component** [6 marks]: Using the MLEnd London Sounds dataset, build a machine learning pipeline that takes as an input an audio segment and predicts whether the audio segment has been recorded indoors or outdoors.\n",
    "2.   **Advanced component** [10 marks]: Formulate your own machine learning problem and build a machine learning solution using the MLEnd London Sounds dataset. \n",
    "\n",
    "Your submission will consist of two Jupyter notebooks, one for the basic component and another one for advanced component. Please **name each notebook**:\n",
    "\n",
    "* ECS7020P_miniproject_basic.ipynb\n",
    "* ECS7020P_miniproject_advanced.ipynb\n",
    "\n",
    "then **zip and submit them toghether**.\n",
    "\n",
    "Each uploaded notebook should include: \n",
    "\n",
    "*   **Text cells**, describing concisely each step and results.\n",
    "*   **Code cells**, implementing each step.\n",
    "*   **Output cells**, i.e. the output from each code cell.\n",
    "\n",
    "and **should have the structure** indicated below. Notebooks might not be run, please make sure that the output cells are saved.\n",
    "\n",
    "How will we evaluate your submission?\n",
    "\n",
    "*   Conciseness in your writing (10%).\n",
    "*   Correctness in your methodology (30%).\n",
    "*   Correctness in your analysis and conclusions (30%).\n",
    "*   Completeness (10%).\n",
    "*   Originality (10%).\n",
    "*   Efforts to try something new (10%).\n",
    "\n",
    "Suggestion: Why don't you use **GitHub** to manage your project? GitHub can be used as a presentation card that showcases what you have done and gives evidence of your data science skills, knowledge and experience. \n",
    "\n",
    "Each notebook should be structured into the following 9 sections:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaGn4ICrfqXZ"
   },
   "source": [
    "# 1 Author\n",
    "\n",
    "**Student Name**:  \n",
    "**Student ID**:  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o38VQkcdKd6k"
   },
   "source": [
    "# 2 Problem formulation\n",
    "\n",
    "Describe the machine learning problem that you want to solve and explain what's interesting about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3BwrtEdLDit"
   },
   "source": [
    "# 3 Machine Learning pipeline\n",
    "\n",
    "Describe your ML pipeline. Clearly identify its input and output, any intermediate stages (for instance, transformation -> models), and intermediate data moving from one stage to the next. It's up to you to decide which stages to include in your pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Audio files \n",
    "- Meta data i.e. where the audio was recorded and by whom\n",
    "    - \n",
    "    -  \n",
    "\n",
    "### Pipeline 1\n",
    "input audio -> mfcc coefficient extraction -- MFCC Coefficients -> data cleanup -- -> PCA dimensionality reduction -- PCA -> Classification Model -> output label (indoor/outdoor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1nDXnzYLLH6"
   },
   "source": [
    "# 4 Transformation stage\n",
    "\n",
    "Describe any transformations, such as feature extraction. Identify input and output. Explain why you have chosen this transformation stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCA for dimensionality reduction\n",
    "- MFCC for feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0F5_kI95LuZ2"
   },
   "source": [
    "# 5 Modelling\n",
    "\n",
    "We'll use the following models to classify our data set and compare the results  \n",
    "1. Support Vector Machine\n",
    "2. Random Forest Classifier\n",
    "\n",
    "Further, we'll use the Grid Search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPTSuaB9L2jU"
   },
   "source": [
    "# 6 Methodology\n",
    "\n",
    "Describe how you will train and validate your models, how model performance is assesssed (i.e. accuracy, confusion matrix, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZQPxztuL9AW"
   },
   "source": [
    "# 7 Dataset\n",
    "\n",
    "Describe the dataset that you will use to create your models and validate them. If you need to preprocess it, do it here. Include visualisations too. You can visualise raw data samples or extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import math\n",
    "\n",
    "import os, sys, re, pickle, glob\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = 'MLEndLS/*.wav'\n",
    "files = glob.glob(sample_path)\n",
    "MLENDLS_df = pd.read_csv('./MLEndLS.csv').set_index('file_id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "aud_data = []\n",
    "labels = []\n",
    "\n",
    "for n in range(0,len(files)):\n",
    "# for n in range(50,100):\n",
    "    a, fs = librosa.load(files[n],sr=None)    \n",
    "    \n",
    "    # MFCC Feature extraction\n",
    "    d_mfcc = librosa.feature.mfcc(y=a, sr=fs)\n",
    "    d_mfcc = librosa.power_to_db(d_mfcc, ref=np.max)\n",
    "    \n",
    "    # Trimming to get a standard input size\n",
    "    d_mfcc = d_mfcc[:,:536].T\n",
    "    d_mfcc = d_mfcc.reshape(1,d_mfcc.shape[0]*d_mfcc.shape[1])\n",
    "    d_mfcc = d_mfcc[0]\n",
    "    \n",
    "    # Filtering errored/invalid data\n",
    "    if len(d_mfcc) < 10720: continue\n",
    "        \n",
    "    if (n%100 == 0): print(n, end=\"\\r\")\n",
    "        \n",
    "    aud_data.append(d_mfcc)\n",
    "    labels.append(MLENDLS_df.loc[files[n].split('/')[-1]].in_out)\n",
    "    \n",
    "print(\"\\nDone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>496.273688</td>\n",
       "      <td>-1627.158133</td>\n",
       "      <td>-663.147782</td>\n",
       "      <td>-642.597629</td>\n",
       "      <td>553.104122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1427.422455</td>\n",
       "      <td>570.942963</td>\n",
       "      <td>338.524282</td>\n",
       "      <td>793.816415</td>\n",
       "      <td>-744.958247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148.189670</td>\n",
       "      <td>137.582675</td>\n",
       "      <td>-708.643630</td>\n",
       "      <td>1054.707158</td>\n",
       "      <td>650.125347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1299.744997</td>\n",
       "      <td>-186.685546</td>\n",
       "      <td>-455.963521</td>\n",
       "      <td>590.182121</td>\n",
       "      <td>431.021297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>985.473985</td>\n",
       "      <td>-1217.602096</td>\n",
       "      <td>-243.111914</td>\n",
       "      <td>143.716085</td>\n",
       "      <td>90.001786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>578.036888</td>\n",
       "      <td>81.470392</td>\n",
       "      <td>505.227408</td>\n",
       "      <td>160.768467</td>\n",
       "      <td>-212.988273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>-852.497143</td>\n",
       "      <td>-279.227471</td>\n",
       "      <td>-792.559738</td>\n",
       "      <td>-528.714587</td>\n",
       "      <td>-72.543250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>1289.524839</td>\n",
       "      <td>245.191524</td>\n",
       "      <td>448.767694</td>\n",
       "      <td>-283.899274</td>\n",
       "      <td>25.959704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>467.655667</td>\n",
       "      <td>-60.914381</td>\n",
       "      <td>520.583015</td>\n",
       "      <td>470.970900</td>\n",
       "      <td>-254.453643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>272.982420</td>\n",
       "      <td>50.169275</td>\n",
       "      <td>104.798200</td>\n",
       "      <td>24.419596</td>\n",
       "      <td>16.486184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2479 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              pc1          pc2         pc3          pc4         pc5\n",
       "1      496.273688 -1627.158133 -663.147782  -642.597629  553.104122\n",
       "2    -1427.422455   570.942963  338.524282   793.816415 -744.958247\n",
       "3      148.189670   137.582675 -708.643630  1054.707158  650.125347\n",
       "4     1299.744997  -186.685546 -455.963521   590.182121  431.021297\n",
       "5      985.473985 -1217.602096 -243.111914   143.716085   90.001786\n",
       "...           ...          ...         ...          ...         ...\n",
       "2475   578.036888    81.470392  505.227408   160.768467 -212.988273\n",
       "2476  -852.497143  -279.227471 -792.559738  -528.714587  -72.543250\n",
       "2477  1289.524839   245.191524  448.767694  -283.899274   25.959704\n",
       "2478   467.655667   -60.914381  520.583015   470.970900 -254.453643\n",
       "2479   272.982420    50.169275  104.798200    24.419596   16.486184\n",
       "\n",
       "[2479 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numComponents = 5\n",
    "pca = PCA(n_components=numComponents)\n",
    "pca.fit(aud_data)\n",
    "\n",
    "projected = pca.transform(aud_data)\n",
    "projected = pd.DataFrame(projected,columns=['pc1','pc2','pc3','pc4','pc5'],index=range(1,len(aud_data)+1))\n",
    "# projected['label'] = labels\n",
    "display(projected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected = projected.drop(columns=[\n",
    "#     'pc3',\n",
    "#     'pc4',\n",
    "#     'pc5',\n",
    "#     'pc6',\n",
    "#     'pc7'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1983, 5) (496, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(projected,labels,test_size=0.20)\n",
    "print(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qf7GN1aeXJI"
   },
   "source": [
    "# 8 Results\n",
    "\n",
    "Carry out your experiments here, explain your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:  SVC(C=1)\n",
      "Average accuracy:  0.7402755514846195\n",
      "Test dataset accuracy: 0.7540322580645161\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "parameters = {'C':[1,2,3,4,5]}\n",
    "\n",
    "svc = svm.SVC()\n",
    "clf_model = GridSearchCV(svc, parameters,cv=5)\n",
    "\n",
    "clf_model.fit(X_train,y_train)\n",
    "\n",
    "print('Hyperparameters: ', clf_model.best_estimator_)\n",
    "print('Average accuracy: ', clf_model.best_score_)\n",
    "print('Test dataset accuracy:', clf_model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Hyperparameters:  RandomForestClassifier(max_depth=5, max_features=2)\n",
      "Best Model Accuracy:  0.7191075526512809\n",
      "Test Data Accuracy: 0.7379032258064516\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'n_estimators':[50,100,200], \n",
    "    'max_features':[1,2,5], \n",
    "    'max_depth':[5,10,20]\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "clf_model = GridSearchCV(rfc, parameters,cv=2)\n",
    "\n",
    "clf_model.fit(X_train,y_train)\n",
    "\n",
    "print('Best Model Hyperparameters: ', clf_model.best_estimator_)\n",
    "print('Best Model Accuracy: ', clf_model.best_score_)\n",
    "print('Test Data Accuracy:', clf_model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSrJCR_cekPO"
   },
   "source": [
    "# 9 Conclusions\n",
    "\n",
    "Your conclusions, improvements, etc should go here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
